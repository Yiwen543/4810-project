# -*- coding: utf-8 -*-
"""tugas-pcvk-3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/xingexu666/tugas-pcvk-3.571d9a68-5b94-4760-be63-ba22dfa7a93a.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20251208/auto/storage/goog4_request%26X-Goog-Date%3D20251208T065251Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D172129b26a58f824fac7b737ed0bd957dec4cb191209b16c183bc6f4ebdac0156a9234a0d776bcec2b913f21dbe32c3d98a4a7047ad11d38a4b785022ba14d59a0b697b5879a3b216194a7c14bbd69dafdb31060f3a87917cf445e10d020e64ef89aa017d511caa168af04a89c54129c6504a3f91195b0a793a6ffeacfa507e13ab8eb4e7d8e25d29b86dac903e2795eeb65f1073cf79f85debb5f5e19ad379402626bcf9f89c497bc852e3cdd6baa249e1575a631414398f6e5485f196ac058d7adfde26ed479462b75b68916dd19077373ae5b50e717d1022ba1dbeb24bd5b195af2e0e5e30bb0e6854387dfaa71e2ee6d1a5ac04e007e9eba256aceafe7db
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("nikhilroxtomar/brain-tumor-segmentation")

print("Path to dataset files:", path)

"""# SETUP"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from scipy import ndimage
from skimage import morphology, filters
from skimage.segmentation import watershed
from skimage.feature import peak_local_max
import os
import glob

IMAGE_PATH = os.path.join('data', 'images')
MASK_PATH = os.path.join('data', 'masks')
OUTPUT_PATH = 'output'

os.makedirs(OUTPUT_PATH, exist_ok=True)

"""# Utility Function"""

def load_image(path, grayscale=False):
    """Load image from path"""
    if grayscale:
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    else:
        img = cv2.imread(path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    return img

def preprocess_image(image):
    """Preprocess image: denoising and normalization"""
    # Convert to grayscale if needed
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    else:
        gray = image.copy()

    # Denoising
    denoised = cv2.GaussianBlur(gray, (5, 5), 0)

    # Normalize
    normalized = cv2.normalize(denoised, None, 0, 255, cv2.NORM_MINMAX)
    # normalized = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX)

    return normalized

def calculate_metrics(pred_mask, true_mask):
    """Calculate segmentation metrics: Dice, IoU, Accuracy"""
    pred_mask = (pred_mask > 0).astype(np.uint8)
    true_mask = (true_mask > 0).astype(np.uint8)

    intersection = np.logical_and(pred_mask, true_mask).sum()
    union = np.logical_or(pred_mask, true_mask).sum()

    # Dice Coefficient
    dice = (2 * intersection) / (pred_mask.sum() + true_mask.sum() + 1e-7)

    # IoU (Jaccard Index)
    iou = intersection / (union + 1e-7)

    # Accuracy
    accuracy = np.mean(pred_mask == true_mask)

    return {
        'dice': dice,
        'iou': iou,
        'accuracy': accuracy
    }

"""# Otsu Thresholding"""

def otsu_thresholding(image):
    """
    Otsu's Automatic Thresholding
    Menghitung threshold optimal secara otomatis
    """
    preprocessed = preprocess_image(image)

    # Apply Otsu's thresholding
    _, binary = cv2.threshold(preprocessed, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # Morphological operations to clean up
    kernel = np.ones((5, 5), np.uint8)
    cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)

    return cleaned

"""# Multiotsu Tresholding"""

def multi_otsu_thresholding(image, n_classes=3):
    """
    Multi-level Otsu Thresholding
    Untuk segmentasi multi-kelas (background, tumor core, edema)
    """
    preprocessed = preprocess_image(image)

    # Apply multi-Otsu thresholding
    thresholds = filters.threshold_multiotsu(preprocessed, classes=n_classes)

    # Create segmented image
    segmented = np.digitize(preprocessed, bins=thresholds)

    # Return binary mask of tumor region (highest intensity class)
    tumor_mask = (segmented == (n_classes - 1)).astype(np.uint8) * 255

    return tumor_mask

"""# KMean Segementation"""

def kmeans_segmentation(image, k=3):
    """
    K-means Clustering Segmentation
    Mengelompokkan pixel berdasarkan intensitas
    """
    preprocessed = preprocess_image(image)

    # Reshape image for K-means
    pixels = preprocessed.reshape(-1, 1)

    # Apply K-means
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    labels = kmeans.fit_predict(pixels)

    # Reshape back to image
    segmented = labels.reshape(preprocessed.shape)

    # Assume tumor is the brightest cluster
    cluster_means = [preprocessed[segmented == i].mean() for i in range(k)]
    tumor_label = np.argmax(cluster_means)

    # Create binary mask
    tumor_mask = (segmented == tumor_label).astype(np.uint8) * 255

    return tumor_mask

"""# Region Growing"""

def region_growing(image, seed=None, threshold=10):
    """
    Region Growing Segmentation
    Menumbuhkan region dari seed point berdasarkan similarity
    """
    preprocessed = preprocess_image(image)
    h, w = preprocessed.shape

    # Auto-select seed if not provided (center of brightest region)
    if seed is None:
        # Find brightest region
        blurred = cv2.GaussianBlur(preprocessed, (15, 15), 0)
        seed = np.unravel_index(np.argmax(blurred), blurred.shape)

    # Initialize
    segmented = np.zeros_like(preprocessed, dtype=np.uint8)
    seed_value = preprocessed[seed]

    # Region growing using flood fill
    mask = np.zeros((h + 2, w + 2), np.uint8)
    cv2.floodFill(preprocessed.copy(), mask, seed[::-1], 255,
                  threshold, threshold, cv2.FLOODFILL_FIXED_RANGE)

    segmented = mask[1:-1, 1:-1]

    return segmented

"""# Watershed Segmentation"""

def watershed_segmentation(image, min_distance=20):
    """
    Watershed Segmentation
    Metode berbasis morfologi untuk memisahkan objek yang overlap
    """
    preprocessed = preprocess_image(image)

    # Thresholding untuk mendapatkan foreground
    _, binary = cv2.threshold(preprocessed, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # Noise removal
    kernel = np.ones((3, 3), np.uint8)
    opening = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=2)

    # Sure background area
    sure_bg = cv2.dilate(opening, kernel, iterations=3)

    # Finding sure foreground area
    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
    _, sure_fg = cv2.threshold(dist_transform, 0.5 * dist_transform.max(), 255, 0)

    # Finding unknown region
    sure_fg = np.uint8(sure_fg)
    unknown = cv2.subtract(sure_bg, sure_fg)

    # Marker labelling
    _, markers = cv2.connectedComponents(sure_fg)
    markers = markers + 1
    markers[unknown == 255] = 0

    # Apply watershed
    img_color = cv2.cvtColor(preprocessed, cv2.COLOR_GRAY2BGR)
    markers = cv2.watershed(img_color, markers)

    # Create binary mask
    segmented = np.zeros_like(preprocessed)
    segmented[markers > 1] = 255

    return segmented

"""# Morphological Operation"""

def morphological_operations(image, operation='closing', kernel_size=5):
    """
    Morphological Operations
    Operations: erosion, dilation, opening, closing
    """
    preprocessed = preprocess_image(image)

    # Initial thresholding
    # _, binary = cv2.threshold(preprocessed, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    binary = kmeans_segmentation(preprocessed)

    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))

    if operation == 'erosion':
        result = cv2.erode(binary, kernel, iterations=1)
    elif operation == 'dilation':
        result = cv2.dilate(binary, kernel, iterations=1)
    elif operation == 'opening':
        result = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
    elif operation == 'closing':
        result = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
    elif operation == 'opening+closing':
        result = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
        result = cv2.morphologyEx(result, cv2.MORPH_CLOSE, kernel)
    else:
        result = binary

    return result

"""# Adaptive Tresholding"""

def adaptive_thresholding(image, block_size=11, c=2):
    """
    Adaptive Thresholding
    Menghitung threshold lokal untuk setiap region
    """
    preprocessed = preprocess_image(image)

    # Apply adaptive thresholding
    binary = cv2.adaptiveThreshold(preprocessed, 255,
                                   cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                   cv2.THRESH_BINARY, block_size, c)

    # Post-processing
    kernel = np.ones((5, 5), np.uint8)
    cleaned = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)

    return cleaned

"""# Visualize"""

def visualize_results(original, mask, segmented, method_name, metrics=None):
    """Visualize original, mask, segmented, and overlay"""
    fig, axes = plt.subplots(1, 4, figsize=(20, 5))

    # Original image
    if len(original.shape) == 3:
        axes[0].imshow(original)
    else:
        axes[0].imshow(original, cmap='gray')
    axes[0].set_title('Original Image')
    axes[0].axis('off')

    # Ground truth mask
    axes[1].imshow(mask, cmap='gray')
    axes[1].set_title('Ground Truth Mask')
    axes[1].axis('off')

    # Segmented result
    axes[2].imshow(segmented, cmap='gray')
    axes[2].set_title(f'Segmented ({method_name})')
    axes[2].axis('off')

    # Overlay
    if len(original.shape) == 3:
        overlay = original.copy()
    else:
        overlay = cv2.cvtColor(original, cv2.COLOR_GRAY2RGB)

    # Create colored mask overlay
    mask_colored = np.zeros_like(overlay)
    mask_colored[:, :, 0] = segmented  # Red channel for prediction
    mask_colored[:, :, 1] = mask  # Green channel for ground truth

    overlay = cv2.addWeighted(overlay, 0.7, mask_colored, 0.3, 0)
    axes[3].imshow(overlay)
    axes[3].set_title('Overlay (Red: Pred, Green: GT)')
    axes[3].axis('off')

    # Add metrics if available
    if metrics:
        fig.suptitle(f'{method_name} - Dice: {metrics["dice"]:.4f}, IoU: {metrics["iou"]:.4f}, Acc: {metrics["accuracy"]:.4f}',
                    fontsize=14, fontweight='bold')

    plt.tight_layout()

"""# Process Image"""

image_files = sorted(os.listdir(IMAGE_PATH))
mask_files = sorted(os.listdir(MASK_PATH))

image_path = os.path.join(IMAGE_PATH, image_files[1])
mask_path = os.path.join(MASK_PATH, mask_files[1])

image = load_image(image_path)
mask = load_image(mask_path, grayscale=True)

otsu = otsu_thresholding(image)
multiotsu = multi_otsu_thresholding(image, n_classes=3)
kmeans = kmeans_segmentation(image, k=3)
rg = region_growing(image)
ws = watershed_segmentation(image)
at = adaptive_thresholding(image)

visualize_results(image, mask, otsu, 'Otsu')
visualize_results(image, mask, multiotsu, 'Multiotsu')
visualize_results(image, mask, kmeans, 'KMeans')
visualize_results(image, mask, rg, 'Region Growing')
visualize_results(image, mask, ws, 'Watershed')
visualize_results(image, mask, at, 'Adaptive Thresholding')

erosion = morphological_operations(image=image, operation='erosion', kernel_size=15)
dilation = morphological_operations(image=image, operation='dilation', kernel_size=15)
opening = morphological_operations(image=image, operation='opening', kernel_size=15)
closing = morphological_operations(image=image, operation='closing', kernel_size=15)
opening_closing = morphological_operations(image=image, operation='opening+closing', kernel_size=15)

visualize_results(image, mask, erosion, 'Erosion', calculate_metrics(erosion, mask))
visualize_results(image, mask, dilation, 'Dilation', calculate_metrics(dilation, mask))
visualize_results(image, mask, opening, 'Opening', calculate_metrics(opening, mask))
visualize_results(image, mask, closing, 'Closing', calculate_metrics(closing, mask))
visualize_results(image, mask, opening_closing, 'Opening + Closing', calculate_metrics(opening_closing, mask))

"""# Countour Adjusment

"""

import cv2
import numpy as np
from typing import Tuple, Optional
from scipy.ndimage import label

def compute_gradient(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)

    gradient = np.sqrt(grad_x**2 + grad_y**2)

    return gradient

def estimate_noise_intensity(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    laplacian = cv2.Laplacian(gray, cv2.CV_64F)
    noise_estimate = np.var(laplacian) / (gray.std() + 1e-10)

    E_nt = min(noise_estimate / 100.0, 1.0)

    return E_nt

def compute_image_std(image):
    if len(image.shape) == 2:
        return np.std(image)

    H, W, C = image.shape
    std_sum = 0

    for c in range(C):
        channel = image[:, :, c]
        mu_c = np.mean(channel)
        std_c = np.sqrt(np.sum((channel - mu_c)**2) / (H * W))
        std_sum += std_c

    sigma = std_sum / C
    return sigma

def extract_contours(segmentation):
    kernel = np.ones((3, 3), np.uint8)
    dilated = cv2.dilate(segmentation.astype(np.uint8), kernel, iterations=1)
    eroded = cv2.erode(segmentation.astype(np.uint8), kernel, iterations=1)

    contours = dilated - eroded
    contours = (contours > 0).astype(np.uint8)

    return contours

def adaptive_gradient_threshold(image, segmentation):
    gradient = compute_gradient(image)
    contours = extract_contours(segmentation)

    N_all = image.shape[0] * image.shape[1]
    N_contour = np.sum(contours > 0)

    if N_contour == 0:
        return np.median(gradient)

    E_nt = estimate_noise_intensity(image)

    N_low = N_all * (1 - E_nt) - N_contour * (1 - 2 * E_nt)
    N_low = max(int(N_low), 0)

    contour_gradients = gradient[contours > 0]
    if len(contour_gradients) == 0:
        Th_0 = np.median(gradient)

    else:
        sorted_gradients = np.sort(contour_gradients)
        idx = min(N_low, len(sorted_gradients) - 1)
        Th_0 = sorted_gradients[idx]

    sigma = compute_image_std(image)
    Th = Th_0 + sigma

    return Th

def compute_color_difference(image, region1_mask, region2_mask):
    if len(image.shape) == 2:
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)

    n = max(np.sum(region1_mask), np.sum(region2_mask))
    if n == 0:
        return 0

    pixels1 = image[region1_mask > 0]
    pixels2 = image[region2_mask > 0]

    if len(pixels1) == 0 or len(pixels2) == 0:
        return 0

    mean1 = np.mean(pixels1, axis=0)
    mean2 = np.mean(pixels2, axis=0)

    C = np.sum(np.abs(mean1 - mean2)) / 3

    return C

def region_expansion(image, segmentation, Th, num_iterations=3):
    H, W = segmentation.shape
    refined_seg = segmentation.copy()
    gradient = compute_gradient(image)

    roi_h = max(H // 20, 3)
    roi_w = max(W // 20, 3)

    labels = np.unique(segmentation)
    labels = labels[labels > 0]

    for iteration in range(num_iterations):
        updated = False

        for label_id in labels:
            region_mask = (refined_seg == label_id).astype(np.uint8)
            contours_cv = cv2.findContours(region_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0]

            if len(contours_cv) == 0:
                continue

            for contour in contours_cv:
                for point in contour:
                    x, y = point[0]

                    y1 = max(0, y - roi_h // 2)
                    y2 = min(H, y + roi_h // 2)
                    x1 = max(0, x - roi_w // 2)
                    x2 = min(W, x + roi_w // 2)

                    roi = refined_seg[y1:y2, x1:x2]
                    roi_gradient = gradient[y1:y2, x1:x2]
                    roi_image = image[y1:y2, x1:x2]

                    unique_labels = np.unique(roi)
                    if len(unique_labels) < 2:
                        continue

                    current_mask = (roi == label_id)
                    other_mask = (roi != label_id) & (roi > 0)

                    if not np.any(other_mask):
                        continue

                    C_roi = compute_color_difference(roi_image, current_mask, other_mask)
                    has_strong_gradient = np.any(roi_gradient > Th)

                    if C_roi < Th / 2 or not has_strong_gradient:
                        continue

                    for dy in [-1, 0, 1]:
                        for dx in [-1, 0, 1]:
                            ny, nx = y + dy, x + dx

                            if ny < 0 or ny >= H or nx < 0 or nx >= W:
                                continue

                            if refined_seg[ny, nx] == label_id:
                                continue

                            neighbor_label = refined_seg[ny, nx]
                            if neighbor_label == 0:
                                continue

                            y_win1 = max(0, ny - 1)
                            y_win2 = min(H, ny + 2)
                            x_win1 = max(0, nx - 1)
                            x_win2 = min(W, nx + 2)

                            window = refined_seg[y_win1:y_win2, x_win1:x_win2]
                            window_image = image[y_win1:y_win2, x_win1:x_win2]

                            current_win_mask = (window == label_id)
                            neighbor_win_mask = (window == neighbor_label)

                            C_win = compute_color_difference(window_image, current_win_mask, neighbor_win_mask)

                            if C_win < Th:
                                refined_seg[ny, nx] = label_id
                                updated = True

        if not updated:
            break

    return refined_seg

def minor_contour_adjustment(image, segmentation, Th):
    H, W = segmentation.shape
    refined_seg = segmentation.copy()
    gradient = compute_gradient(image)

    contours = extract_contours(refined_seg)
    contour_gradients = gradient[contours > 0]
    gradient_mean = np.mean(contour_gradients) if len(contour_gradients) > 0 else np.mean(gradient)

    roi_size = max(H // 20, W // 20, 5)

    labels = np.unique(segmentation)
    labels = labels[labels > 0]

    for direction in ['inward', 'outward']:
        for label_id in labels:
            region_mask = (refined_seg == label_id).astype(np.uint8)
            contours_cv = cv2.findContours(region_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0]

            if len(contours_cv) == 0:
                continue

            for contour in contours_cv:
                for point in contour:
                    x, y = point[0]

                    # Compute search radius L (Equation 11)
                    grad_val = gradient[y, x]
                    if grad_val <= Th:
                        L = 2
                    else:
                        L = int(gradient_mean / Th) + 2

                    # Determine search direction (8-neighborhood)
                    max_grad = grad_val
                    best_pos = None

                    for r in range(1, L + 1):
                        for dy in [-r, 0, r]:
                            for dx in [-r, 0, r]:
                                if dy == 0 and dx == 0:
                                     continue

                                ny, nx = y + dy, x + dx

                                if ny < 0 or ny >= H or nx < 0 or nx >= W:
                                    continue

                                # Check direction (inward/outward)
                                if direction == 'inward':
                                    if refined_seg[ny, nx] != label_id:
                                        continue
                                else:  # outward
                                    if refined_seg[ny, nx] == label_id:
                                        continue

                                # Check color difference in ROI
                                y1 = max(0, ny - roi_size // 2)
                                y2 = min(H, ny + roi_size // 2)
                                x1 = max(0, nx - roi_size // 2)
                                x2 = min(W, nx + roi_size // 2)

                                roi = refined_seg[y1:y2, x1:x2]
                                roi_image = image[y1:y2, x1:x2]

                                current_mask = (roi == label_id)
                                other_mask = (roi != label_id) & (roi > 0)

                                if not np.any(other_mask):
                                    continue

                                C_roi = compute_color_difference(roi_image, current_mask, other_mask)

                                # Check if gradient is stronger
                                if gradient[ny, nx] > max_grad and C_roi > Th:
                                    max_grad = gradient[ny, nx]
                                    best_pos = (ny, nx)

                    # Update contour position
                    if best_pos is not None:
                        if direction == 'outward':
                            refined_seg[best_pos[0], best_pos[1]] = label_id
                        else:
                            refined_seg[y, x] = 0  # Remove from region

    return refined_seg

def remove_small_regions(segmentation, min_size=4):
    refined_seg = segmentation.copy()
    labels = np.unique(segmentation)

    for label_id in labels:
        if label_id == 0:
            continue

        # Find connected components for this label
        region_mask = (segmentation == label_id).astype(np.uint8)
        labeled_array, num_labels = label(region_mask)

        for component_id in range(1, num_labels + 1):
            component_mask = (labeled_array == component_id)
            area = np.sum(component_mask)

            # Remove small regions
            if area <= min_size:
                # Find neighboring label
                kernel = np.ones((3, 3), np.uint8)
                dilated = cv2.dilate(component_mask.astype(np.uint8), kernel, iterations=1)
                boundary = dilated - component_mask.astype(np.uint8)

                neighbor_labels = refined_seg[boundary > 0]
                neighbor_labels = neighbor_labels[neighbor_labels != label_id]
                neighbor_labels = neighbor_labels[neighbor_labels != 0]

                if len(neighbor_labels) > 0:
                    # Merge to most common neighbor
                    unique, counts = np.unique(neighbor_labels, return_counts=True)
                    merge_label = unique[np.argmax(counts)]
                    refined_seg[component_mask] = merge_label

    return refined_seg

def refine(image, segmentation):
    if len(image.shape) == 2:
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)

    Th = adaptive_gradient_threshold(image, segmentation)
    refined_seg = region_expansion(image, segmentation, Th)
    refined_seg = minor_contour_adjustment(image, refined_seg, Th)
    refined_seg = remove_small_regions(refined_seg)

    return refined_seg

segmentation = morphological_operations(image=image, operation='opening', kernel_size=15)
refined_segmentation = refine(image, segmentation)

plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.imshow(image)
plt.title("Original Image")
plt.axis('off')

plt.subplot(1, 3, 2)
plt.imshow(segmentation, cmap='gray')
plt.title("Before Refinement (Original Mask)")
plt.axis('off')

plt.subplot(1, 3, 3)
plt.imshow(refined_segmentation, cmap='gray')
plt.title("After SegEA Refinement")
plt.axis('off')

plt.show()

visualize_results(image, mask, segmentation, 'KMeans', calculate_metrics(segmentation, mask))
visualize_results(image, mask, refined_segmentation, 'KMeans + SegEA', calculate_metrics(refined_segmentation, mask))